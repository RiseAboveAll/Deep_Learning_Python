{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxm9fmkX+bRA+tVFVLH7bR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiseAboveAll/Deep_Learning_Python/blob/master/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7xxzDACRnR2",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPkoooGHQWn",
        "colab_type": "text"
      },
      "source": [
        "<h2>Machine Learning</h2>\n",
        "\n",
        "- Discovers rules to execute a data processing task.  It learns useful representations of input data which get closure to expected output.\n",
        "\n",
        "- Search for useful representations of some input data, within a predefined space of possibilities,using guidance from a feedback signal.\n",
        "\n",
        "- Maps inputs to targets, observing examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyzvbxw-V0ua",
        "colab_type": "text"
      },
      "source": [
        "<h2>Deep Learning</h2>\n",
        "\n",
        "- Learns representations from data that put an emphasis on leaning successive layers.\n",
        "\n",
        "-  Deep in Deep Learning stands for successive layers of representations, i.e number of layers used to contribute to a model.\n",
        "\n",
        "-  Layer representations are learned via neural networks, structured in layers stacked on top of each other.\n",
        "\n",
        "-  Neural network transforms the image into representations that are increasingly different from the orignal image and informative about the final result.\n",
        "\n",
        "-  What transformation does a layer do to its input data is stored in the layers weights, i.e transformation implemented by a layer is parameterized by its weights. Learning means finding a set of values for the weights of all layers in a network such that the network correctly maps inputs to targets.\n",
        "\n",
        "\n",
        "- We need to observe how far the predicted output is from actual. This is done via loss function. Loss function calculate the distance score between the predicted and actual target variable and is termed as cost or score.\n",
        "\n",
        "- This score is used as feedback signal to adjust the value of weights in direction which will lower the loss score. This is implemented by the optimizer.\n",
        "\n",
        "- Initially weights assigned are random. But with every example the network process, weights are adjusted in the direction , where the loss score is minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5isd35OrJk-0",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Ey5mnmG_gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "787d00bd-f35f-4229-9083-074fff46e466"
      },
      "source": [
        "!pip3 install keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bRAFN2DTvft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import models,layers\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-J3VnC_uI3S",
        "colab_type": "text"
      },
      "source": [
        "# Mathematical Building Blocks of Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwidjaC7Rz9F",
        "colab_type": "text"
      },
      "source": [
        "Example : Classify Greyscale images of handwritten digits (28x28) into 10 categories. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56QDLlIyT232",
        "colab_type": "text"
      },
      "source": [
        "<h3> Loading Dataset </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlcClva2T1Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL7Ipt1XUJlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3d9e1aee-f326-4b19-fb80-eda8205684dc"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fEhDmYOUUbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ac5681a0-66eb-486f-9d6e-1ba323c7f98d"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h7EVvitUfyK",
        "colab_type": "text"
      },
      "source": [
        "<h3> Model Workflow :</h3>\n",
        "\n",
        "- Feead neural network the training data\n",
        "\n",
        "- Network will associate images and labels\n",
        "\n",
        "- Network will predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4QEDshZWgoh",
        "colab_type": "text"
      },
      "source": [
        "<h3> Network Architecture </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kVEEI6PUW2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network=models.Sequential()\n",
        "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10,activation='softmax'))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu2MY3eBZWLg",
        "colab_type": "text"
      },
      "source": [
        "Building block of neural networks is the layer. It extracts representations out of the data fed into them .\n",
        "\n",
        "Here, network consist of two dense layers (fully conncected network). To make network fnctional, we need to pick :\n",
        "\n",
        "- Loss Function \n",
        "\n",
        "- Optimizer \n",
        "\n",
        "- Metrics : monitor during training an testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4OftnWzdKaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOnZblx3dcSN",
        "colab_type": "text"
      },
      "source": [
        "Before training, we need to process data by reshaping it into shape which network expects and scaling them in between 0-1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAJl5GiAdrUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images=train_images.reshape((60000,28*28))\n",
        "train_images=train_images.astype('float32')/255.0\n",
        "\n",
        "test_images=test_images.reshape((10000,28*28))\n",
        "test_images=test_images.astype('float32')/255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQywXfZ7fY_m",
        "colab_type": "text"
      },
      "source": [
        "Categorically encode the labels :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3QdMR3cda82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=to_categorical(train_labels)\n",
        "test_labels=to_categorical(test_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cteME9Ubfvc4",
        "colab_type": "text"
      },
      "source": [
        "Train network :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVIeSdkfu1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "e05e2e70-03a3-4105-8c4a-3bbf1682ab45"
      },
      "source": [
        "network.fit(train_images,train_labels,epochs=5,batch_size=128)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2576 - accuracy: 0.9259\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9700\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0671 - accuracy: 0.9796\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9855\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.9883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cc03cf208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKgL0uWgAsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "67908d3b-e136-40d6-9386-1243595f0d20"
      },
      "source": [
        "test_loss,test_acc=network.evaluate(test_images,test_labels)\n",
        "print(test_loss,test_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9787\n",
            "0.06928634643554688 0.9786999821662903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTalHc_-gegy",
        "colab_type": "text"
      },
      "source": [
        "Training Acc : 98.83\n",
        "\n",
        "Test Acc : 97.86\n",
        "\n",
        "There lies overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOQ-GWhpJXZf",
        "colab_type": "text"
      },
      "source": [
        "# Data Representations for Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOyW90tjJqDw",
        "colab_type": "text"
      },
      "source": [
        "<h3> Tensor </h3>\n",
        "\n",
        "It is a container fo data, generalization of matrices to an arbitrary number of dimensions.\n",
        "\n",
        "Types :\n",
        "\n",
        "- Scalars : Contain only one number. To find the number of axes use numpy ndim attribute. \n",
        "\n",
        "eg:\n",
        "\n",
        "```\n",
        "x=np.array(12)\n",
        "x.ndim\n",
        "```\n",
        "\n",
        "- Vectors(1d Tensors)\n",
        "\n",
        "1-D tensors have one axis.\n",
        "\n",
        "eg:\n",
        "\n",
        "```\n",
        "\n",
        "x=np.array([12.,3.,6.,14])\n",
        "x.ndim\n",
        "\n",
        "```\n",
        "\n",
        "- Matrices(2D Tensors)\n",
        "\n",
        "An array of vectors is a matrix or 2D Tensor. It has two axes : rows and columns.\n",
        "\n",
        "```\n",
        "\n",
        "x=np.array([[1,2,3],\n",
        "           [1,2,3],\n",
        "           [1,2,3]])\n",
        "\n",
        "x.ndim\n",
        "```\n",
        "\n",
        "- 3D Tensors:\n",
        "\n",
        "Container having more than 2 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qkEBnsSZK6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f25b69c4-05bb-4e69-e113-7152c9c1de19"
      },
      "source": [
        "digit=train_images[4]\n",
        "plt.imshow(digit,cmap=plt.cm.binary)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f51aca2bcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPRunskaAte1",
        "colab_type": "text"
      },
      "source": [
        "# Tensor Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL8RL8tVAy40",
        "colab_type": "text"
      },
      "source": [
        "<h3> Element wise operation :</h3>\n",
        "\n",
        "Activation function operations are element wise operation, which are independently applied to each entry in the tensor .\n",
        "\n",
        "<h3> Broadcasting </h3>\n",
        "\n",
        "While adding tensors of different shapes, the smaller tensor will be broadcasted to match the shape of larger tensor.\n",
        "\n",
        "It consist of two steps:\n",
        "\n",
        "- Axes are added to the smaller tensor to match the ndim of large tensor\n",
        "\n",
        "- Smaller tensor is repeated along the new axes to match the shape of large tensor\n",
        "\n",
        "<h3> Tensor Dot </h3>\n",
        "\n",
        "Dot product between two matrix is a scalar value.\n",
        "\n",
        "You can take dot product if x.shape[1]==y.shape[0], result will be of shape (x.shape[0],y.shape[1])\n",
        "\n",
        "<h3> Tensor Reshaping </h3>\n",
        "\n",
        "Re-arranging rows and columns to match a target shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFKmtF_2fS7c",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Based Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuphUmRmceCH",
        "colab_type": "text"
      },
      "source": [
        "- Neural layer have two attributes tensors : weights(w) and biases(b), which are trainable parameters.These weights contains information learned by the network from exposure to training data.\n",
        "\n",
        "- Initially weight matrices are randomly initiallized by small random values. Objective is to adjust these weights as per the feedback signal i.e loss .\n",
        "\n",
        "<h3> Training Loop Steps: </3>\n",
        "\n",
        "  - Take a batch of training samples x and corresponding targets y\n",
        "\n",
        "  - Run the network on x (forward pass) to obtain predictions y_pred\n",
        "\n",
        "  - Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y\n",
        "\n",
        "  - Update all weights of the network in a way that slightly reduces the loss on this batch.\n",
        "\n",
        "All mathematical operation being used in network are differentiable and compute the gradient of the loss with regard to the networks cofficients, we can move the coefficients in the opposite direcion from the gradient.\n",
        "\n",
        "<h3> Derivative </h3>\n",
        "\n",
        "Consider f(x)=y, mapping real number x to a new real number y. Because the function is continuous, a small change in x can only result in a small change in y. If we increase x by small amount let say ex, it resullts in small ey change to y.\n",
        "\n",
        "f(x+ex)=y+ey\n",
        "\n",
        "When ex is small enough, around a certain point , it is possible to approximate f as a linear function of slope a , so that ey becomes a*ex.\n",
        "\n",
        "f(x+ex)=y+a*ex\n",
        "\n",
        "a is called derivative of f in p. If a is negative, it means a small change of x around p will decrease f(x) , if a is positive, a small change in x will increase f(x). Absolute value of a tells us how quickly this increase or decrease will happen.\n",
        "\n",
        "<h3> Derivative of a Tensor Operation </h3>\n",
        "\n",
        "Consider : Input Vector -> X , Coefficient/Weight Matrix -> W , Target -> y, Loss Function -> loss. Using W,X we can compute y_pred and compute loss :\n",
        "\n",
        "y_pred =dot(W,X)\n",
        "loss_value=loss(y,y_pred)\n",
        "\n",
        "If we freeze X and y, then we can interpret as a function mapping values of W to loss_value\n",
        "\n",
        "loss_value=f(W)\n",
        "\n",
        "Let us say the current value of W is W0,then the derivative of f in the point W0 is a tensor gradient(f)(W0) with the same shape as W, where each coefficient gradient (f) (W0)[i.j] indicates the direction and magnitude of the change in loss_value you observe when modifying W0[i,j]. Hence, to change W we need to move in the opposite direction of the derivative. We will update W via:\n",
        "\n",
        "W1=W0 - step * gradient(f)(W0)\n",
        "\n",
        "step is needed because gradient (f)(W0) only approximates the curvature when you are close to W0, so you do not want to go too far from W0\n",
        "\n",
        "<h3> Stochastic Gradient Descent </h3>\n",
        "\n",
        "Function minimum is a point where function's derivative is 0. Finding combination of weight values that yield the smallest possible loss function is the objective. We modify parameters little by little based on the given loss value on the given batch.\n",
        "\n",
        "**Steps :**\n",
        "\n",
        "1. Draw a batch of training samples x and corresponding targets y\n",
        "\n",
        "2. Run the network on X to obtain predictions y_pred\n",
        "\n",
        "3. Compute loss of the network on the batch.\n",
        "\n",
        "4. Compute the gradient of the loss with regard to network's parameters\n",
        "\n",
        "5. Move parameters a little in the opposite direction from the gradient\n",
        "\n",
        "Stochastic refers to that each batch of data is drawn at random.\n",
        "\n",
        "It is very important to pick right value for step. If it is too small, the descent down the curve will take many iterations and it could get stuck at local minima. If step is too large, your update may end up takig you to completely random locations on the curve.\n",
        "\n",
        "*Momentum addresses :\n",
        "\n",
        "  a. Convergence Speed\n",
        "\n",
        "  b. Local Minima\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpNohzztAx30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LslMzUHu3Woq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}